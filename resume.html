<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Ramya Reddy Gunreddy | Senior Data Engineer | Data Quality Engineer</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      font-size: 16px;
      line-height: 1.5;
      color: #333;
      background-color: #f9f9f9;
    }

    .resume-container {
      max-width: 800px;
      margin: 0 auto;
      padding: 10px;
      background-color: #fff;
      border-radius: 10px;
      font-size: 14px;
    }

    .resume-header {
      background-color: #fff;
      color: #000;
      padding: 10px;
      border-bottom: 1px solid #333;
      font-size: 18px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .resume-header h1 {
      font-size: 24px;
      margin: 0;
    }

    .resume-header h2 {
      font-size: 20px;
      margin: 0;
    }

    .resume-header .contact-info {
      margin-top: 5px;
      font-size: 14px;
    }

    .resume-header .contact-info a {
      color: #000;
      text-decoration: none;
      margin: 0 5px;
    }

    .resume-header .contact-info a:hover {
      text-decoration: underline;
    }

    .resume-section {
      padding: 10px 20px;
    }


    .resume-section table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 20px;
    }

    .resume-section table, .resume-section th, .resume-section td {
      border: 1px solid #ddd;
    }

    .resume-section th, .resume-section td {
      padding: 8px;
      text-align: left;
    }

    .resume-section th {
      background-color: #f4f4f4;
      font-weight: bold;
    }

    .resume-section td i {
      margin-right: 5px;
    }

    .experience-table td {
      vertical-align: top;
    }

    .experience-table .title {
      font-weight: bold;
    }

    @media print {
      body {
        background-color: #fff;
        color: #000;
        padding: 5px;

      }

      .resume-container {
        background-color: #fff;
        color: #000;
      }

      .resume-header {
        margin-bottom: 5px;
      }

      .resume-section {
        margin-bottom: 10px;
      }

      .resume-section table {
        border: 1px solid #000;
      }

      .resume-section th, .resume-section td {
        padding: 5px;
        font-size: 12px;
      }
    }
  </style>
</head>
<body>
<div class="resume-container">
  <div class="resume-header">
    <h1>Ramya Reddy Gunreddy</h1>
    <h2>Senior Data Engineer | Data Quality Engineer</h2>
    <div class="contact-info">
      <a href="tel:+6588902608"><i class="fas fa-phone"></i> +65 88902608</a>
      | <a href="#"><i class="fas fa-envelope"></i> ramyareddy2026@gmail.com</a>
    </div>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-user"></i> Summary</h2>
    <ul>
      <li><i class="fas fa-database"></i> Experienced Data Engineer with expertise in designing and managing ETL
        pipelines for regulatory reporting and SaaS/On-prem data migrations.
      </li>
      <li><i class="fas fa-server"></i> Proficient in handling large-scale datasets and optimizing pipeline
        performance using Apache Spark, Hive, Hadoop, S3, Databricks, Delta, Snowflake, Gitlab CI, and Airflow.
      </li>
      <li><i class="fas fa-cloud"></i> Skilled in ensuring data accuracy and integrity across cloud and
        on-premises environments.
      </li>
      <li><i class="fas fa-check-circle"></i> Proven track record of achieving high compliance match rates,
        demonstrating the importance of precise data management in the financial sector.
      </li>
    </ul>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-briefcase"></i> Experience</h2>
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Credit Agricole CIB <span><i
          class="fas fa-map-marker-alt"></i> Singapore</span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Oct 2022 - Oct 2024 | Senior Data Engineer
      </p>
      
      <h4><i class="fas fa-trophy"></i> Achievements</h4>
      
      <ul>
        <li>Designed and optimized ETL processes to handle millions of daily counterparty records for DFA
          (Dodd-Frank Act) compliance, significantly improving data accuracy using Apache Spark, HDFS, Apache
          Hive, Airflow, Jupyter Notebooks, and ORC.
        </li>
        <li>Conducted comprehensive data comparisons between production and pre-production environments,
          analyzing thousands of records and achieving a high match rate on compliance metrics, ensuring
          consistency and regulatory adherence.
        </li>
        <li>Automated data validation by creating scripts to verify critical data points (e.g., counterparty
          IDs, LEIs), reducing discrepancies and improving audit readiness, minimizing potential compliance
          risks.
        </li>
        <li> Implemented partitioning and compression techniques to optimize data storage, enhancing query
          performance and reducing costs for large volumes of historical data.
        </li>
        <li> Collaborated closely with compliance teams to ensure data met DFA regulatory standards,
          facilitating timely reporting with no regulatory penalties
        </li>
      </ul>
    </div>
    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Practically 
        <span><i class="fas fa-map-marker-alt"></i> Hyderabad, India</span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Oct 2020 - Nov 2021 | Data Engineer</p>
    
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Designed and optimized data pipelines to process student quiz activity from RDBMS and S3, ensuring accurate and timely academic performance reporting. Utilized Apache Spark, Airflow, Python, S3, Hive, Databricks, and Athena to build scalable ETL workflows.</li>
          <li>Implemented Hadoop ecosystem tools and AWS services (S3, Athena) to enhance scalability and efficiency in data storage and processing.</li>
          <li>Collaborated with cross-functional teams to design and implement data models supporting key app features such as assignment tracking and quiz performance, ensuring data integrity.</li>
          <li>Developed data validation pipelines in Databricks to enhance reporting accuracy, empowering stakeholders with reliable insights for decision-making.</li>
        </ul>
      </div>
    </div>
    
    
    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Wipro 
        <span><i class="fas fa-map-marker-alt"></i> Hyderabad, India</span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Nov 2018 - Oct 2019 | Data Engineer</p>
    
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Designed and implemented ETL pipelines to generate statistical insights from large datasets, optimizing performance between on-prem and cloud-based architectures using Apache Spark, HDFS, S3, Airflow, Hive, Tableau, and Athena.</li>  
          <li>Integrated AWS S3 with Hadoop-based pipelines to facilitate seamless data migration, ensuring efficient storage and compliance.</li>  
          <li>Built and optimized data pipelines to bring data from Oracle ERP to the Data Lake with SuiteAnalytics Connect, ensuring high availability, accuracy, and efficient processing.</li>  
          <li>Collaborated with engineering and product teams to define migration requirements, enforce best practices, and align data pipelines with business needs and compliance standards.</li>  
        </ul>
      </div>
    </div>

    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> eTouch Systems <span><i
          class="fas fa-map-marker-alt"></i> Hyderabad, India </span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Apr 2017 - Jun 2018 | Quality Analyst
      </p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li> Designed and executed test scenarios for web applications, identifying defects and reporting them in JIRA/Excel for stakeholders.
          </li>
        </ul>
      </div>
    </div>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-laptop-code"></i> Technical Skills</h2>
    <table>
      <thead>
      <tr>
        <th>Category</th>
        <th>Details</th>
      </tr>
      </thead>
      <tbody>
      <tr>
        <td><i class="fas fa-database"></i> Datastores</td>
        <td> Databricks Delta, Snowflake, S3, MySQL, Postgres, Kafka, Oracle ERP</td>
      </tr>
      <tr>
        <td><i class="fas fa-tools"></i> Data/AI tools and frameworks</td>
        <td> Apache Spark, Airflow, Hadoop, Databricks, Tableau, Presto, Hive</td>
      </tr>
      <tr>
        <td><i class="fas fa-lock"></i> Domains</td>
        <td> Banking, E-Learning</td>
      </tr>
      <tr>
        <td><i class="fas fa-cogs"></i> DevOps and Infrastructure</td>
        <td> Docker, Gitlab, Jenkins, AWS, Prometheus, Grafana, Elastic, Kibana</td>
      </tr>
      <tr>
        <td><i class="fas fa-code"></i> Programming languages</td>
        <td> Python, Java, SQL</td>
      </tr>
      </tbody>
    </table>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-graduation-cap"></i>Academics</h2>
    <ul>
      <li>Bachelors in Computer Science Engineering â€“ JNTU Hyderabad, India</li>
    </ul>
  </div>
</div>
</body>
</html>
