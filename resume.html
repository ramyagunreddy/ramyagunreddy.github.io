<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Ramya Reddy Gunreddy | Senior Data Engineer | Data Quality Engineer</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      font-size: 16px;
      line-height: 1.5;
      padding: 20px;
      color: #333;
      background-color: #f9f9f9;
    }
    
    .resume-container {
      max-width: 800px;
      margin: 0 auto;
      padding: 10px;
      background-color: #fff;
      border-radius: 10px;
      font-size: 14px;
    }
    
    .resume-header {
      background-color: #fff;
      color: #000;
      padding: 0px 10px 10px 10px;
      border-bottom: 1px solid #333;
      font-size: 18px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    
    .resume-header h1 {
      font-size: 24px;
      margin: 0;
    }
    
    .resume-header h2 {
      font-size: 20px;
      margin: 0;
    }
    
    .resume-header .contact-info {
      font-size: 14px;
    }
    
    .resume-header .contact-info a {
      color: #000;
      text-decoration: none;
      margin: 0 5px;
    }
    
    .resume-header .contact-info a:hover {
      text-decoration: underline;
    }
    
    .resume-section {
      padding: 10px 20px;
    }
    
    .resume-section table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 20px;
    }
    
    .resume-section table, .resume-section th, .resume-section td {
      border: 1px solid #ddd;
    }
    
    .resume-section th, .resume-section td {
      padding: 8px;
      text-align: left;
    }
    
    .resume-section th {
      background-color: #f4f4f4;
      font-weight: bold;
    }
    
    .resume-section td i {
      margin-right: 5px;
    }
    
    .experience-table td {
      vertical-align: top;
    }
    
    .experience-table .title {
      font-weight: bold;
    }
    
    @media print {
      body {
        background-color: #fff;
        color: #000;
        padding: 5px;
      }
      
      .resume-container {
        background-color: #fff;
        color: #000;
      }
      
      .resume-header {
        margin-bottom: 5px;
      }
      
      .resume-section {
        margin-bottom: 10px;
      }
      
      .resume-section table {
        border: 1px solid #000;
      }
      
      .resume-section th, .resume-section td {
        padding: 5px;
        font-size: 12px;
      }
    }
  </style>
</head>
<body>
<div class="resume-container">
  <div class="resume-header">
    <h1>Ramya Reddy Gunreddy</h1>
    <h2>Senior Data Engineer | Data Quality Engineer</h2>
    <div class="contact-info">
      <a href="tel:+6588902608"><i class="fas fa-phone"></i> +65 88902608</a>
      | <a href="#"><i class="fas fa-envelope"></i> ramyareddy2026@gmail.com</a>
    </div>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-user"></i> Summary</h2>
    <ul>
      <li><i class="fas fa-database"></i> Experienced Data Engineer with expertise in designing and managing ETL
        pipelines for regulatory reporting and data migrations.
      </li>
      <li><i class="fas fa-server"></i> Proficient in handling large-scale datasets and optimizing pipeline
        performance using Apache Spark, Hive, Hadoop/S3 and Airflow.
      </li>
      <li><i class="fas fa-cloud"></i> Skilled in ensuring data accuracy and integrity across cloud and
        on-premises environments.
      </li>
      <li><i class="fas fa-check-circle"></i> Proven track record of achieving high compliance match rates,
        demonstrating the importance of precise data management in the financial sector.
      </li>
    </ul>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-briefcase"></i> Experience</h2>
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Crédit Agricole CIB <span><i
          class="fas fa-map-marker-alt"></i> Singapore</span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Oct 2022 - Oct 2024 | Senior Data Engineer
      </p>
      
      <h4><i class="fas fa-trophy"></i> Achievements</h4>
      
      <ul>
        <li>Designed and optimized ETL processes to handle millions of daily counterparty records for DFA
          (Dodd-Frank Act) compliance, significantly improving data accuracy using Apache Spark, HDFS, Apache
          Hive, Airflow, Jupyter Notebooks, and ORC.
        </li>
        <li>Conducted comprehensive data comparisons between production and pre-production environments,
          analyzing thousands of records and achieving a high match rate on compliance metrics, ensuring
          consistency and regulatory adherence.
        </li>
        <li>Automated data validation by creating scripts to verify critical data points (e.g., counterparty
          IDs, LEIs), reducing discrepancies and improving audit readiness, minimizing potential compliance
          risks.
        </li>
        <li> Implemented partitioning and compression techniques to optimize data storage, enhancing query
          performance and reducing costs for large volumes of historical data.
        </li>
        <li> Collaborated closely with compliance teams to ensure data met DFA regulatory standards,
          facilitating timely reporting with no regulatory penalties
        </li>
      </ul>
    </div>
    
    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Practically <span><i
          class="fas fa-map-marker-alt"></i> Hyderabad, India </span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Oct 2020 - Nov 2021 | Data Engineer
      </p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li> Built and optimized data pipelines to process student activity from RDBMS and S3, ensuring
            accurate and timely academic performance reporting. Leveraged Apache Spark, Airflow, Python, S3,
            Hive, and Athena to create scalable and reliable ETL workflows.
          </li>
          <li>Implemented Hadoop ecosystem tools and AWS services (S3, Athena) to enhance scalability and
            efficiency in storing and processing academic activity data.
          </li>
          <li> Partnered with cross-functional teams to design and implement data models that powered key app
            features like assignment tracking and quiz performance, supporting the app's growth and ensuring
            data integrity.
          </li>
          <li> Developed data validation pipelines to ensure the accuracy of insights and reports, enhancing
            decision-making for stakeholders across the platform using Databricks.
          </li>
        </ul>
      </div>
    </div>
    
    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Wipro <span><i
          class="fas fa-map-marker-alt"></i> Hyderabad, India </span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Nov 2018 - Oct 2019 | Data Engineer
      </p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li> Designed and implemented ETL pipelines to enable statistical insights on large datasets,
            comparing the performance and accuracy of on-prem vs. cloud-based data pipelines. Utilized
            Apache Spark, HDFS, S3, Airflow, Hive, and Athena to build scalable, efficient workflows.
          </li>
          <li>
            Integrated AWS S3 with Hadoop-based pipelines to migrate and analyze large datasets,
            ensuring efficient storage and compliance during cloud migrations.
          </li>
          <li> Collaborated with stakeholders across engineering and product teams to define migration
            requirements, implement best practices, and ensure data pipelines met business needs and
            compliance standards.
          </li>
          <li> Conducted post-migration performance benchmarking and validation to guarantee that
            cloud-based pipelines met or exceeded the performance of their on-prem counterparts.
          </li>
        </ul>
      </div>
    </div>
    
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> eTouch Systems <span><i
          class="fas fa-map-marker-alt"></i> Hyderabad, India </span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> Apr 2017 - Jun 2018 | Quality Analyst
      </p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li> Identified and prepared test scenarios of application, then executed test scenarios in
            web applications, reported the defects in JIRA/Excel.
          </li>
        </ul>
      </div>
    </div>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-laptop-code"></i> Technical Skills</h2>
    <table>
      <thead>
      <tr>
        <th>Category</th>
        <th>Details</th>
      </tr>
      </thead>
      <tbody>
      <tr>
        <td><i class="fas fa-database"></i> Datastores</td>
        <td> S3, Presto, MySQL, Postgres, Hive</td>
      </tr>
      <tr>
        <td><i class="fas fa-tools"></i> Data/AI tools and frameworks</td>
        <td> Apache Spark, Airflow, Hadoop, Databricks</td>
      </tr>
      <tr>
        <td><i class="fas fa-lock"></i> Domains</td>
        <td> Banking, E-Learning</td>
      </tr>
      <tr>
        <td><i class="fas fa-cogs"></i> DevOps and Infrastructure</td>
        <td> Docker, Gitlab, Jenkins, AWS, Prometheus, Grafana, Elastic, Kibana</td>
      </tr>
      <tr>
        <td><i class="fas fa-code"></i> Programming languages</td>
        <td> Python, Java, SQL</td>
      </tr>
      </tbody>
    </table>
  </div>
  
  <div class="resume-section">
    <h2><i class="fas fa-graduation-cap"></i>Academics</h2>
    <ul>
      <li>Bachelors in Computer Science Engineering – JNTU Hyderabad, India</li>
    </ul>
  </div>
</div>
</body>
</html>
